{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate quantization on a simple model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/anaconda3/lib/python311.zip', '/opt/anaconda3/lib/python3.11', '/opt/anaconda3/lib/python3.11/lib-dynload', '', '/Users/deyucao/Library/Caches/pypoetry/virtualenvs/quantization-ubRKDRCl-py3.11/lib/python3.11/site-packages', '/var/folders/rx/ym13fcm14d568j0djggdjsrh0000gn/T/tmpg4a_gliw', '/Users/deyucao/Quantization']\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Add the parent directory to the path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "print(sys.path)\n",
    "\n",
    "from core.quantization import quantize_model\n",
    "from core.models.easy_quant import EasyQuantConfig\n",
    "from core.models.squeeze_llm import SqueezeQuantConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple model with only FC layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To keep the quantization process simple, I only used linear layers, which is sufficient for a simple task like MNIST classification.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.5189\n",
      "Epoch [2/5], Loss: 0.3797\n",
      "Epoch [3/5], Loss: 0.3420\n",
      "Epoch [4/5], Loss: 0.3188\n",
      "Epoch [5/5], Loss: 0.2991\n",
      "Test Accuracy: 86.33%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "cal_dataset_size = 1000\n",
    "\n",
    "# Dataset preprocessing\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# Loading the MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "test_and_cal_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Split the test dataset into test and calibration datasets\n",
    "test_dataset, cal_dataset = random_split(\n",
    "    test_and_cal_dataset, [10000 - cal_dataset_size, cal_dataset_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "cal_loader = DataLoader(dataset=cal_dataset, batch_size=cal_dataset_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Model definition\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Convert 28x28 image to 1D\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleLinearModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Model testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLinearModel(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and store the gradients of the loss for the calibration dataset\n",
    "model.eval()\n",
    "\n",
    "# Get the gradients of the loss w.r.t. the weights\n",
    "for images, labels in cal_loader:\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1, Module: Linear(in_features=784, out_features=128, bias=True)\n",
      "Layer: fc2, Module: Linear(in_features=128, out_features=64, bias=True)\n",
      "Layer: fc3, Module: Linear(in_features=64, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_children():\n",
    "    print(f\"Layer: {name}, Module: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded. Model ready for use from epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/ym13fcm14d568j0djggdjsrh0000gn/T/ipykernel_840/2738249724.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    print(f\"Checkpoint loaded. Model ready for use from epoch {start_epoch}.\")\n",
    "else:\n",
    "    print(\"No checkpoint found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_and_predict(model: nn.Module, image: torch.Tensor) -> tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Display an input image and predict the digit using a given model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model for digit classification.\n",
    "        image (torch.Tensor): The input image tensor of shape (1, 28, 28).\n",
    "\n",
    "    Returns:\n",
    "        tuple[int, float]: Predicted digit and the confidence (probability) of the prediction.\n",
    "    \"\"\"\n",
    "    # Display the input image\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Preprocess the image (add batch dimension and flatten)\n",
    "    image = image.view(-1, 28 * 28)  # Shape (1, 784)\n",
    "\n",
    "    # Set model to evaluation mode and make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted_label = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_label].item()\n",
    "\n",
    "    print(f\"Predicted Label: {predicted_label}, Confidence: {confidence:.4f}\")\n",
    "    return predicted_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, test_loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on a test dataset and return the accuracy.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model for digit classification.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 3, Confidence: 0.8902\n",
      "True Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Load a sample image from the test set\n",
    "image, label = test_dataset[1]\n",
    "\n",
    "# Display the image and make a prediction\n",
    "predicted_label, confidence = display_and_predict(model, image)\n",
    "print(f\"True Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize the model with naive method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, all the quantization methods use 3-bit representation unless otherwise noted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model_naive(model: nn.Module, num_bits: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Naively quantize a model to the specified number of bits.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to quantize.\n",
    "        num_bits (int): The number of bits to use for quantization.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The quantized model.\n",
    "    \"\"\"\n",
    "    quantized_model = copy.deepcopy(model)\n",
    "    scale = 2 ** (num_bits - 1) - 1\n",
    "\n",
    "    for (name, module), (name_q, module_q) in zip(\n",
    "        model.named_modules(), quantized_model.named_modules()\n",
    "    ):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            for i in range(module.weight.data.shape[0]):\n",
    "                original_weight = module.weight.data[i]\n",
    "                max_val = torch.max(torch.abs(original_weight))\n",
    "                print(f\"Layer: {name}, channel {i} ,Max: {max_val}\")\n",
    "                print(f\"Quantization range is: {max_val / scale}\")\n",
    "                module_q.weight.data[i] = (\n",
    "                    torch.round(original_weight / (max_val / scale))\n",
    "                    * (max_val / scale)\n",
    "                )\n",
    "\n",
    "    return quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1, channel 0 ,Max: 0.35536086559295654\n",
      "Quantization range is: 0.11845362186431885\n",
      "Layer: fc1, channel 1 ,Max: 0.22237606346607208\n",
      "Quantization range is: 0.07412535697221756\n",
      "Layer: fc1, channel 2 ,Max: 0.33834537863731384\n",
      "Quantization range is: 0.11278179287910461\n",
      "Layer: fc1, channel 3 ,Max: 0.3040206730365753\n",
      "Quantization range is: 0.10134022682905197\n",
      "Layer: fc1, channel 4 ,Max: 0.10032080858945847\n",
      "Quantization range is: 0.03344026952981949\n",
      "Layer: fc1, channel 5 ,Max: 0.30156299471855164\n",
      "Quantization range is: 0.10052099823951721\n",
      "Layer: fc1, channel 6 ,Max: 0.31340792775154114\n",
      "Quantization range is: 0.10446930676698685\n",
      "Layer: fc1, channel 7 ,Max: 0.35004010796546936\n",
      "Quantization range is: 0.11668003350496292\n",
      "Layer: fc1, channel 8 ,Max: 0.26554012298583984\n",
      "Quantization range is: 0.08851337432861328\n",
      "Layer: fc1, channel 9 ,Max: 0.4421647787094116\n",
      "Quantization range is: 0.1473882645368576\n",
      "Layer: fc1, channel 10 ,Max: 0.2849655747413635\n",
      "Quantization range is: 0.09498852491378784\n",
      "Layer: fc1, channel 11 ,Max: 0.2501830458641052\n",
      "Quantization range is: 0.08339434862136841\n",
      "Layer: fc1, channel 12 ,Max: 0.33457866311073303\n",
      "Quantization range is: 0.11152622103691101\n",
      "Layer: fc1, channel 13 ,Max: 0.31533968448638916\n",
      "Quantization range is: 0.10511323064565659\n",
      "Layer: fc1, channel 14 ,Max: 0.26163768768310547\n",
      "Quantization range is: 0.08721256256103516\n",
      "Layer: fc1, channel 15 ,Max: 0.3788616359233856\n",
      "Quantization range is: 0.12628720700740814\n",
      "Layer: fc1, channel 16 ,Max: 0.37915298342704773\n",
      "Quantization range is: 0.12638433277606964\n",
      "Layer: fc1, channel 17 ,Max: 0.2940399944782257\n",
      "Quantization range is: 0.09801333397626877\n",
      "Layer: fc1, channel 18 ,Max: 0.05095130577683449\n",
      "Quantization range is: 0.016983767971396446\n",
      "Layer: fc1, channel 19 ,Max: 0.1474975049495697\n",
      "Quantization range is: 0.04916583374142647\n",
      "Layer: fc1, channel 20 ,Max: 0.26651498675346375\n",
      "Quantization range is: 0.08883833140134811\n",
      "Layer: fc1, channel 21 ,Max: 0.30505040287971497\n",
      "Quantization range is: 0.10168346762657166\n",
      "Layer: fc1, channel 22 ,Max: 0.2908342182636261\n",
      "Quantization range is: 0.09694474190473557\n",
      "Layer: fc1, channel 23 ,Max: 0.19857314229011536\n",
      "Quantization range is: 0.06619104743003845\n",
      "Layer: fc1, channel 24 ,Max: 0.4163469970226288\n",
      "Quantization range is: 0.13878233730793\n",
      "Layer: fc1, channel 25 ,Max: 0.20236970484256744\n",
      "Quantization range is: 0.06745656579732895\n",
      "Layer: fc1, channel 26 ,Max: 0.3198137879371643\n",
      "Quantization range is: 0.10660459846258163\n",
      "Layer: fc1, channel 27 ,Max: 0.07997063547372818\n",
      "Quantization range is: 0.026656879112124443\n",
      "Layer: fc1, channel 28 ,Max: 0.287405401468277\n",
      "Quantization range is: 0.09580180048942566\n",
      "Layer: fc1, channel 29 ,Max: 0.346709668636322\n",
      "Quantization range is: 0.11556988954544067\n",
      "Layer: fc1, channel 30 ,Max: 0.5104007124900818\n",
      "Quantization range is: 0.170133575797081\n",
      "Layer: fc1, channel 31 ,Max: 0.3831768333911896\n",
      "Quantization range is: 0.12772561609745026\n",
      "Layer: fc1, channel 32 ,Max: 0.22092054784297943\n",
      "Quantization range is: 0.07364018261432648\n",
      "Layer: fc1, channel 33 ,Max: 0.2817690074443817\n",
      "Quantization range is: 0.09392300248146057\n",
      "Layer: fc1, channel 34 ,Max: 0.35878798365592957\n",
      "Quantization range is: 0.11959599703550339\n",
      "Layer: fc1, channel 35 ,Max: 0.3338550925254822\n",
      "Quantization range is: 0.11128503084182739\n",
      "Layer: fc1, channel 36 ,Max: 0.2889252007007599\n",
      "Quantization range is: 0.0963084027171135\n",
      "Layer: fc1, channel 37 ,Max: 0.3714056611061096\n",
      "Quantization range is: 0.12380188703536987\n",
      "Layer: fc1, channel 38 ,Max: 0.42880797386169434\n",
      "Quantization range is: 0.14293599128723145\n",
      "Layer: fc1, channel 39 ,Max: 0.24513104557991028\n",
      "Quantization range is: 0.0817103460431099\n",
      "Layer: fc1, channel 40 ,Max: 0.3035449683666229\n",
      "Quantization range is: 0.10118165612220764\n",
      "Layer: fc1, channel 41 ,Max: 0.43086928129196167\n",
      "Quantization range is: 0.14362309873104095\n",
      "Layer: fc1, channel 42 ,Max: 0.2515164017677307\n",
      "Quantization range is: 0.0838387981057167\n",
      "Layer: fc1, channel 43 ,Max: 0.4244549572467804\n",
      "Quantization range is: 0.14148499071598053\n",
      "Layer: fc1, channel 44 ,Max: 0.3477097749710083\n",
      "Quantization range is: 0.11590325832366943\n",
      "Layer: fc1, channel 45 ,Max: 0.2417806088924408\n",
      "Quantization range is: 0.0805935338139534\n",
      "Layer: fc1, channel 46 ,Max: 0.3569278419017792\n",
      "Quantization range is: 0.11897594481706619\n",
      "Layer: fc1, channel 47 ,Max: 0.2282641977071762\n",
      "Quantization range is: 0.0760880634188652\n",
      "Layer: fc1, channel 48 ,Max: 0.24067197740077972\n",
      "Quantization range is: 0.08022399246692657\n",
      "Layer: fc1, channel 49 ,Max: 0.3294473886489868\n",
      "Quantization range is: 0.1098157986998558\n",
      "Layer: fc1, channel 50 ,Max: 0.28628969192504883\n",
      "Quantization range is: 0.09542989730834961\n",
      "Layer: fc1, channel 51 ,Max: 0.29460036754608154\n",
      "Quantization range is: 0.09820012003183365\n",
      "Layer: fc1, channel 52 ,Max: 0.2996627390384674\n",
      "Quantization range is: 0.09988757967948914\n",
      "Layer: fc1, channel 53 ,Max: 0.3397597670555115\n",
      "Quantization range is: 0.11325325816869736\n",
      "Layer: fc1, channel 54 ,Max: 0.2520098090171814\n",
      "Quantization range is: 0.0840032696723938\n",
      "Layer: fc1, channel 55 ,Max: 0.2548859715461731\n",
      "Quantization range is: 0.08496198803186417\n",
      "Layer: fc1, channel 56 ,Max: 0.24818314611911774\n",
      "Quantization range is: 0.08272771537303925\n",
      "Layer: fc1, channel 57 ,Max: 0.3038075268268585\n",
      "Quantization range is: 0.1012691780924797\n",
      "Layer: fc1, channel 58 ,Max: 0.4600149691104889\n",
      "Quantization range is: 0.15333832800388336\n",
      "Layer: fc1, channel 59 ,Max: 0.31437790393829346\n",
      "Quantization range is: 0.10479263216257095\n",
      "Layer: fc1, channel 60 ,Max: 0.2610473036766052\n",
      "Quantization range is: 0.08701577037572861\n",
      "Layer: fc1, channel 61 ,Max: 0.2546129822731018\n",
      "Quantization range is: 0.08487099409103394\n",
      "Layer: fc1, channel 62 ,Max: 0.47555673122406006\n",
      "Quantization range is: 0.15851891040802002\n",
      "Layer: fc1, channel 63 ,Max: 0.32923102378845215\n",
      "Quantization range is: 0.10974367707967758\n",
      "Layer: fc1, channel 64 ,Max: 0.21344804763793945\n",
      "Quantization range is: 0.07114934921264648\n",
      "Layer: fc1, channel 65 ,Max: 0.28711944818496704\n",
      "Quantization range is: 0.09570648521184921\n",
      "Layer: fc1, channel 66 ,Max: 0.2935432493686676\n",
      "Quantization range is: 0.09784775227308273\n",
      "Layer: fc1, channel 67 ,Max: 0.33759844303131104\n",
      "Quantization range is: 0.11253281682729721\n",
      "Layer: fc1, channel 68 ,Max: 0.3412010371685028\n",
      "Quantization range is: 0.1137336790561676\n",
      "Layer: fc1, channel 69 ,Max: 0.21890558302402496\n",
      "Quantization range is: 0.07296852767467499\n",
      "Layer: fc1, channel 70 ,Max: 0.31517869234085083\n",
      "Quantization range is: 0.10505956411361694\n",
      "Layer: fc1, channel 71 ,Max: 0.36344560980796814\n",
      "Quantization range is: 0.12114853411912918\n",
      "Layer: fc1, channel 72 ,Max: 0.2814343273639679\n",
      "Quantization range is: 0.09381144493818283\n",
      "Layer: fc1, channel 73 ,Max: 0.261544406414032\n",
      "Quantization range is: 0.0871814712882042\n",
      "Layer: fc1, channel 74 ,Max: 0.3277042508125305\n",
      "Quantization range is: 0.1092347502708435\n",
      "Layer: fc1, channel 75 ,Max: 0.30568063259124756\n",
      "Quantization range is: 0.10189354419708252\n",
      "Layer: fc1, channel 76 ,Max: 0.32896772027015686\n",
      "Quantization range is: 0.10965590924024582\n",
      "Layer: fc1, channel 77 ,Max: 0.24893374741077423\n",
      "Quantization range is: 0.08297791332006454\n",
      "Layer: fc1, channel 78 ,Max: 0.24287113547325134\n",
      "Quantization range is: 0.08095704764127731\n",
      "Layer: fc1, channel 79 ,Max: 0.27918946743011475\n",
      "Quantization range is: 0.09306315332651138\n",
      "Layer: fc1, channel 80 ,Max: 0.26077911257743835\n",
      "Quantization range is: 0.08692637085914612\n",
      "Layer: fc1, channel 81 ,Max: 0.25551190972328186\n",
      "Quantization range is: 0.08517063409090042\n",
      "Layer: fc1, channel 82 ,Max: 0.3738290071487427\n",
      "Quantization range is: 0.12460967153310776\n",
      "Layer: fc1, channel 83 ,Max: 0.3056888282299042\n",
      "Quantization range is: 0.10189627856016159\n",
      "Layer: fc1, channel 84 ,Max: 0.04630720615386963\n",
      "Quantization range is: 0.015435735695064068\n",
      "Layer: fc1, channel 85 ,Max: 0.3057858347892761\n",
      "Quantization range is: 0.10192861407995224\n",
      "Layer: fc1, channel 86 ,Max: 0.050139665603637695\n",
      "Quantization range is: 0.016713222488760948\n",
      "Layer: fc1, channel 87 ,Max: 0.04797450825572014\n",
      "Quantization range is: 0.01599150337278843\n",
      "Layer: fc1, channel 88 ,Max: 0.27622735500335693\n",
      "Quantization range is: 0.09207578748464584\n",
      "Layer: fc1, channel 89 ,Max: 0.3112567961215973\n",
      "Quantization range is: 0.1037522628903389\n",
      "Layer: fc1, channel 90 ,Max: 0.2554934620857239\n",
      "Quantization range is: 0.08516448736190796\n",
      "Layer: fc1, channel 91 ,Max: 0.2915717661380768\n",
      "Quantization range is: 0.09719058871269226\n",
      "Layer: fc1, channel 92 ,Max: 0.33081504702568054\n",
      "Quantization range is: 0.11027168482542038\n",
      "Layer: fc1, channel 93 ,Max: 0.30019310116767883\n",
      "Quantization range is: 0.10006436705589294\n",
      "Layer: fc1, channel 94 ,Max: 0.23729854822158813\n",
      "Quantization range is: 0.07909951359033585\n",
      "Layer: fc1, channel 95 ,Max: 0.33196794986724854\n",
      "Quantization range is: 0.11065598577260971\n",
      "Layer: fc1, channel 96 ,Max: 0.34063947200775146\n",
      "Quantization range is: 0.11354649066925049\n",
      "Layer: fc1, channel 97 ,Max: 0.3205116391181946\n",
      "Quantization range is: 0.1068372130393982\n",
      "Layer: fc1, channel 98 ,Max: 0.2877826690673828\n",
      "Quantization range is: 0.09592755883932114\n",
      "Layer: fc1, channel 99 ,Max: 0.2683750092983246\n",
      "Quantization range is: 0.08945833891630173\n",
      "Layer: fc1, channel 100 ,Max: 0.29294639825820923\n",
      "Quantization range is: 0.09764879941940308\n",
      "Layer: fc1, channel 101 ,Max: 0.24182845652103424\n",
      "Quantization range is: 0.08060948550701141\n",
      "Layer: fc1, channel 102 ,Max: 0.08604241162538528\n",
      "Quantization range is: 0.02868080325424671\n",
      "Layer: fc1, channel 103 ,Max: 0.23486436903476715\n",
      "Quantization range is: 0.07828812301158905\n",
      "Layer: fc1, channel 104 ,Max: 0.4106767773628235\n",
      "Quantization range is: 0.13689225912094116\n",
      "Layer: fc1, channel 105 ,Max: 0.2736969292163849\n",
      "Quantization range is: 0.0912323072552681\n",
      "Layer: fc1, channel 106 ,Max: 0.2899136245250702\n",
      "Quantization range is: 0.09663787484169006\n",
      "Layer: fc1, channel 107 ,Max: 0.07414205372333527\n",
      "Quantization range is: 0.024714017286896706\n",
      "Layer: fc1, channel 108 ,Max: 0.3852340281009674\n",
      "Quantization range is: 0.12841133773326874\n",
      "Layer: fc1, channel 109 ,Max: 0.2745044231414795\n",
      "Quantization range is: 0.09150147438049316\n",
      "Layer: fc1, channel 110 ,Max: 0.3510265648365021\n",
      "Quantization range is: 0.11700885742902756\n",
      "Layer: fc1, channel 111 ,Max: 0.30166178941726685\n",
      "Quantization range is: 0.10055392980575562\n",
      "Layer: fc1, channel 112 ,Max: 0.3348519802093506\n",
      "Quantization range is: 0.1116173267364502\n",
      "Layer: fc1, channel 113 ,Max: 0.3056302070617676\n",
      "Quantization range is: 0.10187673568725586\n",
      "Layer: fc1, channel 114 ,Max: 0.30235058069229126\n",
      "Quantization range is: 0.10078352689743042\n",
      "Layer: fc1, channel 115 ,Max: 0.2082294523715973\n",
      "Quantization range is: 0.0694098174571991\n",
      "Layer: fc1, channel 116 ,Max: 0.22328229248523712\n",
      "Quantization range is: 0.07442743331193924\n",
      "Layer: fc1, channel 117 ,Max: 0.2902590036392212\n",
      "Quantization range is: 0.09675300121307373\n",
      "Layer: fc1, channel 118 ,Max: 0.34792906045913696\n",
      "Quantization range is: 0.11597635596990585\n",
      "Layer: fc1, channel 119 ,Max: 0.23218445479869843\n",
      "Quantization range is: 0.07739482074975967\n",
      "Layer: fc1, channel 120 ,Max: 0.3576194941997528\n",
      "Quantization range is: 0.1192064955830574\n",
      "Layer: fc1, channel 121 ,Max: 0.2277487963438034\n",
      "Quantization range is: 0.07591626793146133\n",
      "Layer: fc1, channel 122 ,Max: 0.4020441174507141\n",
      "Quantization range is: 0.13401471078395844\n",
      "Layer: fc1, channel 123 ,Max: 0.2906832993030548\n",
      "Quantization range is: 0.09689443558454514\n",
      "Layer: fc1, channel 124 ,Max: 0.04796319827437401\n",
      "Quantization range is: 0.015987733379006386\n",
      "Layer: fc1, channel 125 ,Max: 0.3252945840358734\n",
      "Quantization range is: 0.10843152552843094\n",
      "Layer: fc1, channel 126 ,Max: 0.21120692789554596\n",
      "Quantization range is: 0.07040230929851532\n",
      "Layer: fc1, channel 127 ,Max: 0.42825499176979065\n",
      "Quantization range is: 0.14275166392326355\n",
      "Layer: fc2, channel 0 ,Max: 0.3230588436126709\n",
      "Quantization range is: 0.10768628120422363\n",
      "Layer: fc2, channel 1 ,Max: 0.26281291246414185\n",
      "Quantization range is: 0.08760430663824081\n",
      "Layer: fc2, channel 2 ,Max: 0.2776041328907013\n",
      "Quantization range is: 0.09253471344709396\n",
      "Layer: fc2, channel 3 ,Max: 0.29561692476272583\n",
      "Quantization range is: 0.09853897243738174\n",
      "Layer: fc2, channel 4 ,Max: 0.27121660113334656\n",
      "Quantization range is: 0.09040553122758865\n",
      "Layer: fc2, channel 5 ,Max: 0.24665847420692444\n",
      "Quantization range is: 0.08221948891878128\n",
      "Layer: fc2, channel 6 ,Max: 0.33723822236061096\n",
      "Quantization range is: 0.11241274327039719\n",
      "Layer: fc2, channel 7 ,Max: 0.26743873953819275\n",
      "Quantization range is: 0.08914624899625778\n",
      "Layer: fc2, channel 8 ,Max: 0.23949256539344788\n",
      "Quantization range is: 0.07983085513114929\n",
      "Layer: fc2, channel 9 ,Max: 0.10922865569591522\n",
      "Quantization range is: 0.03640955314040184\n",
      "Layer: fc2, channel 10 ,Max: 0.26096999645233154\n",
      "Quantization range is: 0.08698999881744385\n",
      "Layer: fc2, channel 11 ,Max: 0.22119005024433136\n",
      "Quantization range is: 0.07373001426458359\n",
      "Layer: fc2, channel 12 ,Max: 0.28829604387283325\n",
      "Quantization range is: 0.09609868377447128\n",
      "Layer: fc2, channel 13 ,Max: 0.47776925563812256\n",
      "Quantization range is: 0.15925641357898712\n",
      "Layer: fc2, channel 14 ,Max: 0.26815250515937805\n",
      "Quantization range is: 0.08938416838645935\n",
      "Layer: fc2, channel 15 ,Max: 0.11201523244380951\n",
      "Quantization range is: 0.03733840957283974\n",
      "Layer: fc2, channel 16 ,Max: 0.23079368472099304\n",
      "Quantization range is: 0.07693123072385788\n",
      "Layer: fc2, channel 17 ,Max: 0.24033159017562866\n",
      "Quantization range is: 0.08011052757501602\n",
      "Layer: fc2, channel 18 ,Max: 0.28072410821914673\n",
      "Quantization range is: 0.09357470273971558\n",
      "Layer: fc2, channel 19 ,Max: 0.24876075983047485\n",
      "Quantization range is: 0.08292025327682495\n",
      "Layer: fc2, channel 20 ,Max: 0.22492055594921112\n",
      "Quantization range is: 0.07497351616621017\n",
      "Layer: fc2, channel 21 ,Max: 0.263734370470047\n",
      "Quantization range is: 0.087911456823349\n",
      "Layer: fc2, channel 22 ,Max: 0.29019734263420105\n",
      "Quantization range is: 0.09673244506120682\n",
      "Layer: fc2, channel 23 ,Max: 0.40360331535339355\n",
      "Quantization range is: 0.13453443348407745\n",
      "Layer: fc2, channel 24 ,Max: 0.32193616032600403\n",
      "Quantization range is: 0.10731205344200134\n",
      "Layer: fc2, channel 25 ,Max: 0.12344478070735931\n",
      "Quantization range is: 0.04114826023578644\n",
      "Layer: fc2, channel 26 ,Max: 0.27626875042915344\n",
      "Quantization range is: 0.09208958595991135\n",
      "Layer: fc2, channel 27 ,Max: 0.2701830565929413\n",
      "Quantization range is: 0.0900610163807869\n",
      "Layer: fc2, channel 28 ,Max: 0.22575175762176514\n",
      "Quantization range is: 0.07525058835744858\n",
      "Layer: fc2, channel 29 ,Max: 0.23040945827960968\n",
      "Quantization range is: 0.07680315524339676\n",
      "Layer: fc2, channel 30 ,Max: 0.3022184371948242\n",
      "Quantization range is: 0.1007394790649414\n",
      "Layer: fc2, channel 31 ,Max: 0.25236961245536804\n",
      "Quantization range is: 0.08412320166826248\n",
      "Layer: fc2, channel 32 ,Max: 0.3252996504306793\n",
      "Quantization range is: 0.10843321681022644\n",
      "Layer: fc2, channel 33 ,Max: 0.19134116172790527\n",
      "Quantization range is: 0.06378038972616196\n",
      "Layer: fc2, channel 34 ,Max: 0.32791945338249207\n",
      "Quantization range is: 0.10930648446083069\n",
      "Layer: fc2, channel 35 ,Max: 0.37634414434432983\n",
      "Quantization range is: 0.1254480481147766\n",
      "Layer: fc2, channel 36 ,Max: 0.22072048485279083\n",
      "Quantization range is: 0.07357349246740341\n",
      "Layer: fc2, channel 37 ,Max: 0.3106841742992401\n",
      "Quantization range is: 0.1035613939166069\n",
      "Layer: fc2, channel 38 ,Max: 0.2781375050544739\n",
      "Quantization range is: 0.09271249920129776\n",
      "Layer: fc2, channel 39 ,Max: 0.185799241065979\n",
      "Quantization range is: 0.06193308159708977\n",
      "Layer: fc2, channel 40 ,Max: 0.17258527874946594\n",
      "Quantization range is: 0.05752842500805855\n",
      "Layer: fc2, channel 41 ,Max: 0.2960449755191803\n",
      "Quantization range is: 0.09868165850639343\n",
      "Layer: fc2, channel 42 ,Max: 0.19054853916168213\n",
      "Quantization range is: 0.06351617723703384\n",
      "Layer: fc2, channel 43 ,Max: 0.4161401391029358\n",
      "Quantization range is: 0.13871337473392487\n",
      "Layer: fc2, channel 44 ,Max: 0.23926468193531036\n",
      "Quantization range is: 0.07975489646196365\n",
      "Layer: fc2, channel 45 ,Max: 0.27811384201049805\n",
      "Quantization range is: 0.09270461648702621\n",
      "Layer: fc2, channel 46 ,Max: 0.3457134962081909\n",
      "Quantization range is: 0.11523783206939697\n",
      "Layer: fc2, channel 47 ,Max: 0.3997341990470886\n",
      "Quantization range is: 0.13324473798274994\n",
      "Layer: fc2, channel 48 ,Max: 0.36736008524894714\n",
      "Quantization range is: 0.12245336174964905\n",
      "Layer: fc2, channel 49 ,Max: 0.32051411271095276\n",
      "Quantization range is: 0.10683804005384445\n",
      "Layer: fc2, channel 50 ,Max: 0.3842008113861084\n",
      "Quantization range is: 0.12806694209575653\n",
      "Layer: fc2, channel 51 ,Max: 0.26713651418685913\n",
      "Quantization range is: 0.08904550224542618\n",
      "Layer: fc2, channel 52 ,Max: 0.22432869672775269\n",
      "Quantization range is: 0.07477623224258423\n",
      "Layer: fc2, channel 53 ,Max: 0.1942312866449356\n",
      "Quantization range is: 0.0647437646985054\n",
      "Layer: fc2, channel 54 ,Max: 0.2925828993320465\n",
      "Quantization range is: 0.0975276306271553\n",
      "Layer: fc2, channel 55 ,Max: 0.26532652974128723\n",
      "Quantization range is: 0.08844217658042908\n",
      "Layer: fc2, channel 56 ,Max: 0.2127874493598938\n",
      "Quantization range is: 0.0709291473031044\n",
      "Layer: fc2, channel 57 ,Max: 0.22404488921165466\n",
      "Quantization range is: 0.07468163222074509\n",
      "Layer: fc2, channel 58 ,Max: 0.3071754574775696\n",
      "Quantization range is: 0.102391816675663\n",
      "Layer: fc2, channel 59 ,Max: 0.3959382474422455\n",
      "Quantization range is: 0.13197942078113556\n",
      "Layer: fc2, channel 60 ,Max: 0.27054983377456665\n",
      "Quantization range is: 0.09018328040838242\n",
      "Layer: fc2, channel 61 ,Max: 0.2890412211418152\n",
      "Quantization range is: 0.09634707123041153\n",
      "Layer: fc2, channel 62 ,Max: 0.24209646880626678\n",
      "Quantization range is: 0.08069882541894913\n",
      "Layer: fc2, channel 63 ,Max: 0.29132962226867676\n",
      "Quantization range is: 0.09710987657308578\n",
      "Layer: fc3, channel 0 ,Max: 0.22941339015960693\n",
      "Quantization range is: 0.07647112756967545\n",
      "Layer: fc3, channel 1 ,Max: 0.34893059730529785\n",
      "Quantization range is: 0.11631020158529282\n",
      "Layer: fc3, channel 2 ,Max: 0.3592052459716797\n",
      "Quantization range is: 0.11973508447408676\n",
      "Layer: fc3, channel 3 ,Max: 0.29171472787857056\n",
      "Quantization range is: 0.09723824262619019\n",
      "Layer: fc3, channel 4 ,Max: 0.2759190499782562\n",
      "Quantization range is: 0.09197301417589188\n",
      "Layer: fc3, channel 5 ,Max: 0.5781508684158325\n",
      "Quantization range is: 0.19271695613861084\n",
      "Layer: fc3, channel 6 ,Max: 0.2907019853591919\n",
      "Quantization range is: 0.09690066426992416\n",
      "Layer: fc3, channel 7 ,Max: 0.4365493059158325\n",
      "Quantization range is: 0.14551644027233124\n",
      "Layer: fc3, channel 8 ,Max: 0.4136887490749359\n",
      "Quantization range is: 0.13789625465869904\n",
      "Layer: fc3, channel 9 ,Max: 0.3073176443576813\n",
      "Quantization range is: 0.10243921726942062\n"
     ]
    }
   ],
   "source": [
    "quantized_model_naive = quantize_model_naive(model, num_bits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1\n",
      "Original Weights: tensor([[ 0.0263,  0.0155, -0.0133,  0.0298,  0.0578,  0.0150,  0.0745,  0.1274,\n",
      "          0.2277,  0.2080]])\n",
      "Quantized Weights: tensor([[0.0000, 0.0000, -0.0000, 0.0000, 0.0000, 0.0000, 0.1185, 0.1185, 0.2369,\n",
      "         0.2369]])\n",
      "tensor(0.3554) tensor(-0.3554)\n"
     ]
    }
   ],
   "source": [
    "# Compare the weights of the original and quantized models\n",
    "for (name, module), (name_q, module_q) in zip(\n",
    "    model.named_modules(), quantized_model_naive.named_modules()\n",
    "):\n",
    "    if name == \"fc1\":\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Original Weights: {module.weight.data[:1, :10]}\")\n",
    "        print(f\"Quantized Weights: {module_q.weight.data[:1, :10]}\")\n",
    "        print(module_q.weight.data[:1].max(), module_q.weight.data[:1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.79%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "accuracy_naive = evaluate_model(quantized_model_naive, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the simplest naive quantization method can achieve a good accuracy with a simple model like this, with a degradation of only about 4%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize the model with EasyQuant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without outlier isolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing module: fc1\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 128 output channels\n",
      "Quantization completed in 2.48 seconds\n",
      "Quantizing module: fc2\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 64 output channels\n",
      "Quantization completed in 1.45 seconds\n",
      "Quantizing module: fc3\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 10 output channels\n",
      "Quantization completed in 1.21 seconds\n"
     ]
    }
   ],
   "source": [
    "config_easy = EasyQuantConfig(learning_rate=1e-3, num_epochs=100)\n",
    "\n",
    "# Quantize the model\n",
    "\n",
    "quantized_model_easy = quantize_model(\n",
    "    model,\n",
    "    \"EasyQuant\",\n",
    "    config_easy,\n",
    "    num_bits=3,\n",
    "    verbose=True,\n",
    "    retain_outliers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1\n",
      "Original Weights: tensor([[ 0.0263,  0.0155, -0.0133,  0.0298,  0.0578,  0.0150,  0.0745,  0.1274,\n",
      "          0.2277,  0.2080,  0.1752,  0.0559,  0.0654,  0.1111,  0.0797,  0.0335,\n",
      "         -0.0209,  0.0666,  0.3014,  0.2802]])\n",
      "Quantized Weights: tensor([[0.0000, 0.0000, 0.0000, 0.0586, 0.0586, 0.0000, 0.0586, 0.1172, 0.2344,\n",
      "         0.2344, 0.1758, 0.0586, 0.0586, 0.1172, 0.0586, 0.0586, 0.0000, 0.0586,\n",
      "         0.2344, 0.2344]])\n"
     ]
    }
   ],
   "source": [
    "# Look at the parameters of each layer in the quantized model\n",
    "\n",
    "for (name, module), (name_q, module_q) in zip(\n",
    "    model.named_modules(), quantized_model_easy.named_modules()\n",
    "):\n",
    "    if name == \"fc1\":\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Original Weights: {module.weight.data[:1,:20]}\")\n",
    "        print(\n",
    "            f\"Quantized Weights: {module_q.quantization_executor.reconstruct_layer()[:1,:20]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By optimizing the quantization range to minimize reconstruction error, the reconstructed weights better resemble the original weights than the naive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.83%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "accuracy_easy = evaluate_model(quantized_model_easy, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 3, Confidence: 0.6365\n"
     ]
    }
   ],
   "source": [
    "# Load a sample image from the test set\n",
    "image, label = test_dataset[1]\n",
    "\n",
    "# Display the image and make a prediction\n",
    "predicted_label, confidence = display_and_predict(quantized_model_easy, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obervation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EasyQuant method (without outlier isolation) was able to achieve a degradation of as little as 2.5 %.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With outlier isolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing module: fc1\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 128 output channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deyucao/Quantization/core/models/easy_quant.py:298: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  outlier_weights = outlier_weights.to_sparse_csr()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization completed in 2.28 seconds\n",
      "Quantizing module: fc2\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 64 output channels\n",
      "Quantization completed in 1.43 seconds\n",
      "Quantizing module: fc3\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 10 output channels\n",
      "Quantization completed in 1.27 seconds\n"
     ]
    }
   ],
   "source": [
    "quantized_model_easy_out_iso = quantize_model(\n",
    "    model,\n",
    "    \"EasyQuant\",\n",
    "    config_easy,\n",
    "    num_bits=3,\n",
    "    verbose=True,\n",
    "    retain_outliers=True,\n",
    "    outlier_threshold=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1\n",
      "Original Weights: tensor([[ 0.0263,  0.0155, -0.0133,  0.0298,  0.0578,  0.0150,  0.0745,  0.1274,\n",
      "          0.2277,  0.2080,  0.1752,  0.0559,  0.0654,  0.1111,  0.0797,  0.0335,\n",
      "         -0.0209,  0.0666,  0.3014,  0.2802]])\n",
      "Quantized Weights: tensor([[ 0.0351,  0.0000,  0.0000,  0.0351,  0.0703,  0.0000,  0.0703,  0.1406,\n",
      "          0.2277,  0.2080,  0.1752,  0.0703,  0.0703,  0.1054,  0.0703,  0.0351,\n",
      "         -0.0351,  0.0703,  0.3014,  0.2802]])\n"
     ]
    }
   ],
   "source": [
    "# Look at the parameters of each layer in the quantized model\n",
    "\n",
    "for (name, module), (name_q, module_q) in zip(\n",
    "    model.named_modules(), quantized_model_easy_out_iso.named_modules()\n",
    "):\n",
    "    if name == \"fc1\":\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Original Weights: {module.weight.data[:1,:20]}\")\n",
    "        print(\n",
    "            f\"Quantized Weights: {module_q.quantization_executor.reconstruct_layer()[:1,:20]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.07%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "accuracy_easy_out_iso = evaluate_model(quantized_model_easy_out_iso, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier isolation in this case was able to recover the accuracy by about 0.25 %, which verifies the importance of outlier weights and more optimized quantization range with only normal weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize the model with SqueezeLLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Sensitivity-based weighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing module: fc1\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 128 output channels\n",
      "Quantization completed in 2.34 seconds\n",
      "Quantizing module: fc2\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 64 output channels\n",
      "Quantization completed in 1.58 seconds\n",
      "Quantizing module: fc3\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 10 output channels\n",
      "Quantization completed in 1.59 seconds\n"
     ]
    }
   ],
   "source": [
    "config_squeeze = SqueezeQuantConfig(k_means_max_iter=100, use_sensitivity=False)\n",
    "\n",
    "# Quantize the model\n",
    "\n",
    "quantized_model_squeeze = quantize_model(\n",
    "    model,\n",
    "    \"SqueezeQuant\",\n",
    "    config_squeeze,\n",
    "    num_bits=3,\n",
    "    verbose=True,\n",
    "    retain_outliers=True,\n",
    "    outlier_threshold=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Test Accuracy: 85.74%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "quantized_model_squeeze.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = quantized_model_squeeze(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Quantized Model Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SqueezeLLM based quantization method (with outlier isolation but without sensitivity-based weighting) led to a decrease in accuracy of about 0.5 %.\\\n",
    "This result is even better than that of the EasyQuant algorithm, which indicates the effectiveness of non-uniform quantization method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1\n",
      "Original Weights: tensor([[ 0.0263,  0.0155, -0.0133,  0.0298,  0.0578,  0.0150,  0.0745,  0.1274,\n",
      "          0.2277,  0.2080,  0.1752,  0.0559,  0.0654,  0.1111,  0.0797,  0.0335,\n",
      "         -0.0209,  0.0666,  0.3014,  0.2802]])\n",
      "Quantized Normal Weights: tensor([[ 1,  1, -4,  1, -3,  1, -3,  0, -4, -4, -4, -3, -3,  0, -3,  1, -1, -3,\n",
      "         -4, -4]], dtype=torch.int8)\n",
      "Reconstructed Weights: tensor([[ 0.0280,  0.0280, -0.0032,  0.0280,  0.0630,  0.0280,  0.0630,  0.1103,\n",
      "          0.2277,  0.2080,  0.1752,  0.0630,  0.0630,  0.1103,  0.0630,  0.0280,\n",
      "         -0.0316,  0.0630,  0.3014,  0.2802]])\n"
     ]
    }
   ],
   "source": [
    "# Look at the parameters of each layer in the quantized model\n",
    "\n",
    "for (name, module), (name_q, module_q) in zip(\n",
    "    model.named_modules(), quantized_model_squeeze.named_modules()\n",
    "):\n",
    "    if name == \"fc1\":\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Original Weights: {module.weight.data[:1,:20]}\")\n",
    "        print(\n",
    "            f\"Quantized Normal Weights: {module_q.quantization_executor.normal_weights[:1,:20]}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Reconstructed Weights: {module_q.quantization_executor.reconstruct_layer()[:1,:20]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Sensitivity-based weighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing module: fc1\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 128 output channels\n",
      "Quantization completed in 2.67 seconds\n",
      "Quantizing module: fc2\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 64 output channels\n",
      "Quantization completed in 1.63 seconds\n",
      "Quantizing module: fc3\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 10 output channels\n",
      "Quantization completed in 1.54 seconds\n"
     ]
    }
   ],
   "source": [
    "config_squeeze_weighted = SqueezeQuantConfig(k_means_max_iter=100, use_sensitivity=True)\n",
    "\n",
    "# Quantize the model\n",
    "\n",
    "quantized_model_squeeze_weighted = quantize_model(\n",
    "    model,\n",
    "    \"SqueezeQuant\",\n",
    "    config_squeeze_weighted,\n",
    "    num_bits=3,\n",
    "    verbose=True,\n",
    "    retain_outliers=True,\n",
    "    outlier_threshold=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.72%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "accuracy = evaluate_model(quantized_model_squeeze_weighted, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: fc1\n",
      "Original Weights: tensor([[ 0.0450,  0.0145,  0.0132,  0.0735,  0.0662,  0.0706,  0.0331,  0.0595,\n",
      "         -0.0001,  0.0194,  0.0090,  0.0231,  0.0112, -0.0571,  0.0014, -0.0363,\n",
      "         -0.0093,  0.0543,  0.0987,  0.0547]])\n",
      "Quantized Normal Weights: tensor([[ 3, -2, -2, -3, -3, -3,  3, -3,  0, -2, -2, -2, -2,  1,  0, -4,  0, -3,\n",
      "          2, -3]], dtype=torch.int8)\n",
      "Reconstructed Weights: tensor([[ 0.0388,  0.0143,  0.0143,  0.0648,  0.0648,  0.0648,  0.0388,  0.0648,\n",
      "         -0.0075,  0.0143,  0.0143,  0.0143,  0.0143, -0.0647, -0.0075, -0.0352,\n",
      "         -0.0075,  0.0648,  0.1079,  0.0648]])\n"
     ]
    }
   ],
   "source": [
    "# Look at the parameters of each layer in the quantized model\n",
    "\n",
    "for (name, module), (name_q, module_q) in zip(\n",
    "    model.named_modules(), quantized_model_squeeze_weighted.named_modules()\n",
    "):\n",
    "    if name == \"fc1\":\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Original Weights: {module.weight.data[:1,:20]}\")\n",
    "        print(\n",
    "            f\"Quantized Normal Weights: {module_q.quantization_executor.normal_weights[:1,:20]}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Reconstructed Weights: {module_q.quantization_executor.reconstruct_layer()[:1,:20]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the sensitivity of weights in K-means clustering did not have any recognizable effect on the accuracy of the model.\\\n",
    "With many trials, the increase in accuracy averaged to about 0.1 %, which is negligible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with 2-bit representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing module: fc1\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 128 output channels\n",
      "Quantization completed in 2.42 seconds\n",
      "Quantizing module: fc2\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 64 output channels\n",
      "Quantization completed in 1.60 seconds\n",
      "Quantizing module: fc3\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 10 output channels\n",
      "Quantization completed in 1.51 seconds\n"
     ]
    }
   ],
   "source": [
    "config_squeeze_weighted = SqueezeQuantConfig(k_means_max_iter=100, use_sensitivity=True)\n",
    "\n",
    "# Quantize the model\n",
    "\n",
    "quantized_model_squeeze_weighted_2bit = quantize_model(\n",
    "    model,\n",
    "    \"SqueezeQuant\",\n",
    "    config_squeeze_weighted,\n",
    "    num_bits=2,\n",
    "    verbose=True,\n",
    "    retain_outliers=True,\n",
    "    outlier_threshold=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.12%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized model\n",
    "accuracy = evaluate_model(quantized_model_squeeze_weighted_2bit, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2-bit (4 values) can achieve an almost comparable accuracy as the original float32 model, which is a remarkable result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with 1-bit representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing module: fc1\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 128 output channels\n",
      "Quantization completed in 2.51 seconds\n",
      "Quantizing module: fc2\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 64 output channels\n",
      "Quantization completed in 1.53 seconds\n",
      "Quantizing module: fc3\n",
      "Using torch.int8 for quantization.\n",
      "Quantizing 10 output channels\n",
      "Quantization completed in 1.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Quantize the model\n",
    "\n",
    "quantized_model_squeeze_weighted_1bit = quantize_model(\n",
    "    model,\n",
    "    \"SqueezeQuant\",\n",
    "    config_squeeze_weighted,\n",
    "    num_bits=1,\n",
    "    verbose=True,\n",
    "    retain_outliers=True,\n",
    "    outlier_threshold=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_model(quantized_model_squeeze_weighted_1bit, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 2-bit was the bottom line for this model and dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantization-ubRKDRCl-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
